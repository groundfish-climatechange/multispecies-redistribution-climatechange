---
title: "Custom functions for use in species distribution modeling"
author: "Owen Liu"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup2, include=FALSE}
# devtools::install_github("pbs-assess/sdmTMB")
library(sdmTMB)
library(tidyverse)
library(lubridate)
library(sf)
library(here)
library(Hmisc)
library(concaveman)
knitr::opts_chunk$set(echo = TRUE)
options(dplyr.summarise.inform=FALSE)
```

# Purpose

Write functions utilizing `sdmTMB` to fit and project models for west coast groundfish based on hindcast ROMS oceanographic data. There are also functions to facilitate post-processing and visualization of model outputs.

# Functions for Fitting

## Prepare Species' Data

This function selects a species' data from the trawl survey data, normalizes/scales the environmental data

```{r}
prepare_species <- function(dat,spp){
  dat_sub <- dat %>% 
    dplyr::filter(species==spp) %>% 
    
    # rescale depth, oxygen, and temp to be N(0,1)
    mutate(across(c(depth_trawl,mean_temp_roms_30,mean_oxygen_roms_30),~(scale(.) %>% as.vector()),.names="{.col}_norm")) %>% 
    
    # add a year indicator
    mutate(year=lubridate::year(date))
}
```

## sdmTMB Model Function

Write a function that runs sdmTMB to fit a single model. It will call the previous `prepare_species` function to make the appropriate species data. The environmental variable names are not generic (always `mean_temp_roms_30_norm` and `mean_oxygen_roms_30_norm` for fitting to the ROMS data).

```{r}
run_sdmTMB <- function(dat,spp,use_depth=F,time_vary=F,spatial_field=T,env_spline=F,spline_k=3){
  # filter data for species
  modeldat <- prepare_species(dat,spp=spp)
  
  # make spde
  spde <- make_mesh(modeldat,xy_cols = c('longitude','latitude'), 
                   cutoff = 20)
  
  # model formula
  formula <- paste0("cpue_kg_km2 ~ ")
  
  # make the environmental effects
  enviro <- paste("mean_temp_roms_30_norm + I(mean_temp_roms_30_norm^2) + mean_oxygen_roms_30_norm + I(mean_oxygen_roms_30_norm^2)")
  # wiggly environmental relationships?
  enviro <- ifelse(env_spline, paste0("s(mean_temp_roms_30_norm,k=",spline_k,") + ",
                                      "s(mean_oxygen_roms_30_norm,k=",spline_k,")"),
                   enviro)
  # if depth effect, add to model formla
  if(use_depth) {
    formula = paste0(formula, " + depth_trawl_norm + I(depth_trawl_norm^2)")
  }
  
  time_formula = "~ -1"
  if(time_vary) {
    time_formula = paste0(time_formula, " + ", enviro)
    time_varying = as.formula(time_formula)
    time = "year"
  } else {
    formula = paste0(formula, " + ", enviro)
    time_varying = NULL
    time = "year"
  }
  
  print('running model.')
  m <- try( sdmTMB(
    formula = as.formula(formula),
    time_varying = time_varying,
    mesh = spde,
    time = time,
    family = tweedie(link = "log"),
    data = modeldat,
    anisotropy = FALSE,
    spatial = spatial_field,
    #extra_time argument necessary for prediction?
    extra_time=1980:2100),
  silent=F)

  if(class(m)=="try-error"){
    print(paste("Error."))
  }else{
    print(paste("Model for",spp,"complete."))
  }

  # return(m)
  return(m)

}
```

## Cross Validation Function

Similar to the function above, this function implements 2-fold cross-validation in order to return the CV log-likelihood for use in model stacking and model ensembles.

```{r}
run_sdmTMB_cv <- function(dat,spp,nknots=400,use_depth=F,time_vary=F,spatial_field=T,env_spline=F,spline_k=3,return_what='loglik'){
  # filter data for species
  modeldat <- prepare_species(dat,spp=spp)
  
  # make spde
  spde <- make_mesh(modeldat,xy_cols = c('longitude','latitude'), 
                   cutoff = 20)
  
  # model formula
  formula <- paste0("cpue_kg_km2 ~ ")
  
  # make the environmental effects
  enviro <- paste("mean_temp_roms_30_norm + I(mean_temp_roms_30_norm^2) + mean_oxygen_roms_30_norm + I(mean_oxygen_roms_30_norm^2)")
  # wiggly environmental relationships?
  enviro <- ifelse(env_spline, paste0("s(mean_temp_roms_30_norm,k=",spline_k,") + ",
                                      "s(mean_oxygen_roms_30_norm,k=",spline_k,")"),
                   enviro)
  # if depth effect, add to model formla
  if(use_depth) {
    formula = paste0(formula, " + depth_trawl_norm + I(depth_trawl_norm^2)")
  }
  
  time_formula = "~ -1"
  if(time_vary) {
    time_formula = paste0(time_formula, " + ", enviro)
    time_varying = as.formula(time_formula)
    time = "year"
  } else {
    formula = paste0(formula, " + ", enviro)
    time_varying = NULL
    time = "year"
  }
  
  set.seed(41389) # for reproducibility
  test_set = sample(1:nrow(modeldat), size = round(0.1*nrow(modeldat)), replace=FALSE)
  modeldat$fold = 1
  modeldat$fold[test_set] = 2 
  
  print('running 2-fold CV.')
  
  m_cv <- try( sdmTMB_cv( 
    formula = as.formula(formula),
    k_folds=2,
    parallel = TRUE,
    fold_ids = modeldat$fold,
    time_varying = time_varying,
    mesh = spde,
    time = time,
    family = tweedie(link = "log"),
    data = modeldat,
    anisotropy = FALSE,
    spatial = spatial_field
  ),
  silent=T)
  if(class(m_cv)=='try-error'){
    print(paste('Error.'))
  } else{
    # tem <- m_cv %>% pluck('data')
    # print(paste('data is class',class(tem)))
    total_pred_ll = m_cv %>% 
      pluck('data') %>% 
      dplyr::filter(cv_fold==2) %>% 
      pluck('cv_loglik') %>% 
      sum()
    if(return_what=='model') return(m_cv)
    else return(total_pred_ll)
  }
}
```

## Model Stacking Function

This function takes a list of models from running the equations, stacks their posterior predictive distributions, and returns appropriate likelihood-based model weights for use in creating ensemble predictions.

```{r}
sdmTMB_stacking <- function (model_list, include_folds = NULL) 
{
    n_models <- length(model_list)
    if (is.null(include_folds)) {
        n_folds <- max(model_list[[1]]$data$cv_fold)
        include_folds <- seq_len(n_folds)
    }
    X <- matrix(0, nrow = nrow(model_list[[1]]$data), ncol = n_models)
    for (i in 1:n_models) X[, i] = model_list[[i]]$data$cv_loglik
    X <- X[which(model_list[[1]]$data$cv_fold %in% include_folds), 
        ]
    X <- exp(X)
    tot_ll = function(p, X) {
        z <- matrix(exp(p)/sum(exp(p)), ncol = 1)
        k <- log(X%*%z)
        -sum(k[which(!is.infinite(k))])
    }
    o <- optim(par = runif(n_models), fn = tot_ll, X = X)
    weights <- exp(o$par)/sum(exp(o$par))
    return(weights)
}
```

## Model Fitting Wrapper

This final, wrapper function uses the functions above to fit a series of models using `run_sdmTMB`, compare them to one another using `run_sdmTMB_cv` and `sdmTMB_stacking`, and output a nested data frame including all models, their associated options (e.g., inclusion of spatial fields, linear or GAM-type environmental relationships), and importantly, their weights to use in the ensembling of model predictions.


```{r}
model_species <- function(spp,data){
  
  models_to_run <-crossing(spp,spatial_field=c(F,T),env_spline=c(F,T)) %>%
      mutate(model_num=row_number())
  
  out <- models_to_run %>% 
    mutate(model=purrr::pmap(list(spp=spp,spatial_field=spatial_field,env_spline=env_spline),run_sdmTMB,dat=data)) %>%
    mutate(model_cv=purrr::pmap(list(spp=spp,spatial_field=spatial_field,env_spline=env_spline),run_sdmTMB_cv,dat=data,return_what="model"))
  
  model_weights <- try(sdmTMB_stacking(out$model_cv))
  if(class(model_weights)=='try-error'){
    print(paste('Error in model stacking.'))
    out$weight=NA
  } else{
    out$weight=model_weights
  }

  out
}
```

# Model Fit Statistics and Visualization

Functions to visualize and save model fits.

## Deviance Explained

```{r}
calc_deviance_ensemble <- function(model_df){
  fit <- model_df$model[[1]]
  dat <- fit$data
  null <- sdmTMB(cpue_kg_km2 ~ 1,
                 spatial="off",
                 mesh = fit$mesh,
                 data = fit$data)
  null_dev <- -2 * as.numeric(logLik(null))
  
  log_lik <- unlist(lapply(model_df$model, logLik))
  
  resid_dev <- -2 * log_lik
  
  dev_explained <- 100 * (null_dev - resid_dev)/null_dev
  
  tibble(null_dev=null_dev,resid_dev=resid_dev,dev_explained=dev_explained)
}
```

## Model Ensemble Table

```{r}
report_model_ensemble <- function(model_df){
  weights_table <- model_df %>% dplyr::select(-model,-model_cv,-model_num)
  dev <- calc_deviance_ensemble(model_df)$dev_explained
  weights_table$DevianceExplained=dev
  convergence <- purrr::map_int(model_df$model,function(m){m$model$convergence})
  weights_table$Convergence <- convergence
  range_params <- purrr::map_dbl(model_df$model,function(m){
    tidy(m,effects='ran_pars') %>% slice(1) %>% pull(estimate)
  })
  weights_table$sumloglik <- purrr::map_dbl(model_df$model_cv,pluck("sum_loglik"))
  weights_table$Matern_range <- range_params
  weights_table
}
```

## QQ plots

```{r}
make_qq_plots <- function(model_df){
  spp <- model_df %>% pluck("model",1,'data','species') %>% unique()
  sppdat <- prepare_species(trawl_roms_utm,spp)
  
  qqp <- purrr::map(model_df$model,function(m){
    r <- residuals(m)[1:nrow(sppdat),1] %>% as_tibble()
    resids <- sppdat %>% mutate(resid=r$value)
    qq <- ggplot(resids,aes(sample=resid))+stat_qq()+stat_qq_line()+
      labs(x="Expected",y="Observed")+coord_equal()+
      theme(panel.background = element_rect(color='black'))
    qq
  })
  cowplot::plot_grid(plotlist=qqp,nrow=1,labels=c(1:4))
}
```

## Weighted Spatial Residuals

```{r}
map_weighted_residuals<-function(model_df){
  resids <- purrr::map2(model_df$weight,model_df$model,function(x,y){
    x*residuals(y)
  }) %>% reduce(`+`)
  
  dat <- model_df$model[[1]]$data %>% 
    mutate(w.resid=c(resids)) %>% 
    dplyr::select(latitude,longitude,year,w.resid) %>% 
    filter(year %in% c(2003:2010))
  
  dat_sf <- st_as_sf(dat,coords=c("longitude","latitude"),crs="+proj=utm +zone=10 +datum=WGS84 +units=km")
  
  bbox <- st_bbox(dat_sf)
  ggplot()+
    geom_sf(data=coast,col=NA,fill="gray50")+
    geom_sf(data=dat_sf,size=0.5,aes(col=w.resid))+
    scale_color_gradient2()+
    coord_sf(datum=NA)+
    xlim(bbox[1],bbox[3])+ylim(bbox[2],bbox[4])+
    labs(x="",y="",color="Weighted\nResidual")+
    theme(legend.position = c(0.7,0.6))
}
```

## Visualize Species Environmental Niches

```{r,fig.width=8}
make_spp_concave_hull <- function(ens_preds,yr_vec=1980:2022,sppname,concavity=2,lt=0,threshold=0.05,esm='ipsl'){
  vartemp <- paste0("mean_bt_30d_",esm)
  varoxy <- paste0("mean_oxy_bottom_30d_",esm)
  df <- ens_preds %>% 
    filter(year %in% yr_vec) %>%
    mutate(mean_est=exp(mean_est)) %>%
    filter(mean_est>=quantile(mean_est,threshold)) %>% 
    ungroup() %>% 
    dplyr::select(all_of(c(vartemp,varoxy))) %>% 
    as.matrix()
    # st_as_sf(coords=c("mean_bt_30d_ipsl","mean_oxy_bottom_30d_ipsl"))
  p <- df %>% 
    concaveman(concavity = concavity,length_threshold = lt) %>% 
    as_tibble() %>% 
    mutate(spp=sppname)
  p
}

make_fitted_env_niches <- function(simsdf,gcm,sppname){
  d <- simsdf %>% 
    filter(esm==gcm) %>%
    pivot_longer(contains('sim'),names_to="sim",values_to="est") %>% 
    group_by(year,longitude,latitude,lat,lon,depth_m,esm) %>% 
    summarise(mean_est=mean(est,na.rm=T)) %>% 
    ungroup() %>% 
    left_join(roms,by=c("year", "longitude", "latitude", "lat", "lon"))
  niches <- purrr::map_df(c(0.05,0.5,0.75,0.95),function(thresh){
    make_spp_concave_hull(ens_preds=d,yr_vec=1985:2010,sppname=sppname,threshold=thresh,esm=gcm,lt=50,concavity = 3) %>% 
      mutate(threshold=thresh)
  })
  niches_plot <- ggplot(niches,aes(V1,V2,color=as.factor(threshold)))+
    geom_polygon(fill=NA,size=1.25)+
    scale_x_continuous(limits=c(0,14),breaks=seq(0,14,by=2))+
    scale_y_continuous(limits=c(0,280),breaks=seq(0,250,by=50))+
    labs(y="Bottom Oxygen (mmol/m3)",x="Bottom Temperature",color="Quantile of\nCPUE values",
       title=paste(tools::toTitleCase(sppname),toupper(gcm),"\n1985-2010"))+
    theme(legend.position=c(0.25,0.7),
          panel.background = element_rect(color='black'))
  niches_plot
}
```

# Functions for Projection

## Ensemble Predictions

To create ensemble predictions, we calculate predictions for each species' model separately, then weight them using the weights established in model fitting (i.e., from `sdmTMB_stacking`). This function takes as input the dataframe result of the `model_species` function above, then makes ensemble predictions using the projections from an ESM of choice (Hadley, GFDL, or IPSL). Returns a dataframe of predicted log CPUE. Importantly, right now this function only handles models that were fit with temperature and oxygen data (and, optionally, spatial random effects).

```{r}
# this function is meant to be run with a tibble that includes a list of models that all are fit on the same data, with a common set of predictors
# if nsim > 0, simulate from the joint precision matrix to establish uncertainty
ensemble_predictions <- function(model_df,gcm='hadl',nsims=0){
  tic('projecting ensemble model.')
  # use the first model in the list to pull out the data
  original_model_data <- model_df %>% pluck('model',1,'data')
  # need to use the original (hindcast) environmental data to scale the projected data
  mean_t <- mean(original_model_data$mean_temp_roms_30,na.rm=T)
  sd_t <- sd(original_model_data$mean_temp_roms_30,na.rm=T)
  mean_oxy <- mean(original_model_data$mean_oxygen_roms_30,na.rm=T)
  sd_oxy <- sd(original_model_data$mean_oxygen_roms_30,na.rm=T)
 
  # create a new tibble with the projected data for the chosen gcm
  newdata <- roms %>% 
    left_join(roms_ll,by=c("lat","lon")) %>% 
    drop_na() %>% 
    dplyr::select(year,lat,lon,latitude,longitude,depth_m,contains(paste0("30d_",gcm)))
  
  temperature <- newdata %>% dplyr::select(contains('bt')) %>% 
    set_names('temperature') %>% 
    mutate(mean_temp_roms_30_norm=(temperature-mean_t)/sd_t)
  
  oxygen <- newdata %>% dplyr::select(contains('oxy')) %>% 
    set_names('oxygen') %>% 
    mutate(mean_oxygen_roms_30_norm=(oxygen-mean_oxy)/sd_oxy)

  newdata <- newdata %>% 
    bind_cols(temperature) %>% 
    bind_cols(oxygen) %>% 
    dplyr::select(-temperature,-oxygen) %>%
    mutate(year=as.double(year))
  
  # years to predict
  yrs <- sort(unique(newdata$year))
  
  # model weights
  w <- model_df %>% pluck('weight')
  if(all(is.na(w))) w = rep(1,length(w))
  
  model_list <- model_df %>% pluck('model')
  
  # make the predictions for all 4 models
  set.seed(41389) # for reproducibility and consistency
  if(nsims==0){
      all_predictions <- purrr::map2_df(model_list,w,function(m,weight){
        preds <- predict(m,newdata=newdata,return_tmb_object=F,extra_time=yrs,nsim=nsims) %>% 
        mutate(weight=weight)
        preds
    })
      
    ens_preds <- all_predictions %>% 
      group_by(year,longitude,latitude,lat,lon,depth_m) %>% 
      summarise(ens_est=weighted.mean(est,weight)) %>% 
      ungroup() %>% 
      mutate(esm=gcm)
        
  } else {
      # tic('testing times')
      all_predictions <- purrr::map2(model_list,w,function(m,weight){
        # 10 sims = 25s; 50 sims = 50s; 100 sims= 65s
        # apply the model weight to ALL simulations
        preds <- predict(m,newdata=newdata,return_tmb_object=F,extra_time=yrs,nsim=nsims)*weight
        preds
      }) %>%
        # then add them at the end
        reduce(`+`) %>% 
      # reform back into a dataframe and add identifiers from newdata
        as_tibble(.name_repair='minimal') %>% set_names(paste0('sim',1:100))
      ens_preds <- newdata %>% 
        dplyr::select(year,longitude,latitude,lat,lon,depth_m) %>% 
        bind_cols(all_predictions) %>% 
        mutate(esm=gcm)
      # toc()
  }
  # For 4 models, with 100 sims, took ~300s or about 5 minutes
  toc()
  ens_preds
}
```

# Visualizing Outputs

After models have been fit and projected using trawl survey and ROMS data, we have a lot of ways to visualize the outputs. We ran sdmTMB models and projected them under multiple future climate scenarios, as well as produced 100 simulations, varying parameter values by pulling randomly from the model's joint precision matrix. These functions are to produce figures based on these multiple simulations, including visualization of spread and uncertainty.

## Ensemble Index of Abundance

Ensemble abundance index with `sdmTMB::get_index_sims`

```{r}
make_index_sims <- function(model_df,gcm="hadl",nsims=100){
  # tic('projecting ensemble model.')
  # use the first model in the list to pull out the data
  original_model_data <- model_df %>% pluck('model',1,'data')
  # need to use the original (hindcast) environmental data to scale the projected data
  mean_t <- mean(original_model_data$mean_temp_roms_30,na.rm=T)
  sd_t <- sd(original_model_data$mean_temp_roms_30,na.rm=T)
  mean_oxy <- mean(original_model_data$mean_oxygen_roms_30,na.rm=T)
  sd_oxy <- sd(original_model_data$mean_oxygen_roms_30,na.rm=T)
  
  # create a new tibble with the projected data for the chosen gcm
  newdata <- roms %>% 
    left_join(roms_ll,by=c("lat","lon")) %>% 
    drop_na() %>% 
    dplyr::select(year,lat,lon,latitude,longitude,depth_m,contains(paste0("30d_",gcm)))
  
  temperature <- newdata %>% dplyr::select(contains('bt')) %>% 
    set_names('temperature') %>% 
    mutate(mean_temp_roms_30_norm=(temperature-mean_t)/sd_t)
  
  oxygen <- newdata %>% dplyr::select(contains('oxy')) %>% 
    set_names('oxygen') %>% 
    mutate(mean_oxygen_roms_30_norm=(oxygen-mean_oxy)/sd_oxy)

  newdata <- newdata %>% 
    bind_cols(temperature) %>% 
    bind_cols(oxygen) %>% 
    dplyr::select(-temperature,-oxygen) %>%
    mutate(year=as.double(year))
  
  # years to predict
  yrs <- sort(unique(newdata$year))
  
  # model weights
  w <- model_df %>% pluck('weight')
  if(all(is.na(w))) w = rep(1,length(w))
  
  model_list <- model_df %>% pluck('model')
  
  # make the predictions for all 4 models
  set.seed(41389) # for reproducibility and consistency
  all_predictions <- purrr::map2_df(model_list,w,function(m,weight){
    # 10 sims = 25s; 50 sims = 50s; 100 sims= 65s
    # apply the model weight to ALL simulations
    # preds <- predict(m,newdata=newdata,return_tmb_object=F,extra_time=yrs,nsim=nsims)*weight
    preds <- predict(m,newdata=newdata,return_tmb_object=F,extra_time=yrs,nsim=nsims)
    inds <- get_index_sims(preds) %>% mutate(wt=weight)
    inds
  })
  
  # smooth with a 5 year running mean
  out <- all_predictions %>% 
    group_by(year) %>%
    summarise(wtd.log_est=wtd.mean(log_est,weights=wt),
              wtd.se_est=wtd.mean(se,weights=wt)) %>% 
    mutate(esm=toupper(gcm)) %>% 
    mutate(l1=lag(wtd.log_est,1),
           l2=lag(wtd.log_est,2),
           l3=lag(wtd.log_est,3),
           l4=lag(wtd.log_est,4),
           l5=lag(wtd.se_est,5),
           lse1=lag(wtd.se_est,1),
           lse2=lag(wtd.se_est,2),
           lse3=lag(wtd.se_est,3),
           lse4=lag(wtd.se_est,4),
           lse5=lag(wtd.se_est,5)) %>% 
    mutate(wtd.log_est_smooth=(l1+l2+l3+l4+l5)/5,
           wtd.se_est_smooth=(lse1+lse2+lse3+lse4+lse5)/5) %>% 
    dplyr::select(year,esm,wtd.log_est_smooth,wtd.se_est_smooth)
  
  out 
}
```

## Distance to Shore Change

```{r}
calc_rel_dist_to_shore <- function(sims_df){
  
  d <- sims_df %>% 
    left_join(roms_dist_to_coast,by=c("longitude","latitude")) %>% 
    group_by(esm,year,lat) %>% 
    summarise(across(contains("sim"),function(x) sum(exp(x)/sum(exp(x))*km_to_coast))) %>% 
    ungroup() %>% 
    pivot_longer(contains('sim'),names_to='sim',values_to='dist')
}
```

## Depth Changes

Fraction of population less than 700 fathoms (1280m) over time.

```{r}
calc_depth_frac <- function(sims_df,start_year=2020,end_year=2100){
  
  d <- sims_df %>% 
    filter(year>=start_year,year<=end_year) %>%
    rename(depth=depth_m) %>% 
    mutate(is_deep=depth < -1280) %>% 
    mutate(across(contains('sim'),exp)) %>% 
    group_by(esm,year) %>% 
    summarise(across(contains('sim'),function(x)sum(x[!is_deep]/sum(x)))) %>%
    ungroup() %>% 
    pivot_longer(contains('sim'),names_to='sim',values_to='frac')
  
}
```

Difference in cumulative depth distribution.

```{r}
plot_depth_distribution_sims <- function(ens_preds,histyrs=1985:2010,futyrs=2075:2100){
  yhist <- ens_preds %>% 
    filter(year %in% histyrs) %>%
    mutate(cpue=exp(median_est),cpue5=exp(est5),cpue95=exp(est95)) %>% 
    rename(depth=depth_m) %>% 
    group_by(depth) %>% 
    summarise(cpue=mean(cpue,na.rm=T),
              cpue5=mean(cpue5,na.rm=T),
              cpue95=mean(cpue95,na.rm=T)) %>% 
    ungroup() %>%
    # group_by(year) %>%
    mutate(prop_cpue=cpue/sum(cpue,na.rm=T),
           prop_cpue5=cpue5/sum(cpue5,na.rm=T),
           prop_cpue95=cpue95/sum(cpue95,na.rm=T)) %>%
    arrange(desc(depth)) %>%
    mutate(cum_cpue=cumsum(prop_cpue),
           cum_cpue5=cumsum(prop_cpue5),
           cum_cpue95=cumsum(prop_cpue95)) %>%
    ungroup() %>%
    mutate(period="1985-2010")
  
  yfut <- ens_preds %>% 
    filter(year %in% futyrs) %>%
    mutate(cpue=exp(median_est),cpue5=exp(est5),cpue95=exp(est95)) %>% 
    rename(depth=depth_m) %>% 
    group_by(depth) %>% 
    summarise(cpue=mean(cpue,na.rm=T),
              cpue5=mean(cpue5,na.rm=T),
              cpue95=mean(cpue95,na.rm=T)) %>% 
    ungroup() %>%
    # group_by(year) %>% 
    mutate(prop_cpue=cpue/sum(cpue,na.rm=T),
           prop_cpue5=cpue5/sum(cpue5,na.rm=T),
           prop_cpue95=cpue95/sum(cpue95,na.rm=T)) %>%
    arrange(desc(depth)) %>%
    mutate(cum_cpue=cumsum(prop_cpue),
           cum_cpue5=cumsum(prop_cpue5),
           cum_cpue95=cumsum(prop_cpue95)) %>%
    ungroup() %>%
    mutate(period="2075-2100")
  
  y <- bind_rows(yhist,yfut)
  
  y %>% 
    ggplot(aes(depth,cum_cpue,ymax=cum_cpue95,ymin=cum_cpue5,col=period,fill=period))+
    geom_ribbon(alpha=0.5)+
    geom_line(size=1)+
    xlim(-2000,0)+
    # 700 fathom line
    geom_vline(xintercept=-1280.16,linetype=2)+
    coord_flip()+
    guides(color='none',fill='none')+
    scale_color_manual(values=c("#2271B2","#d55e00"))+
    scale_fill_manual(values=c("#2271B2","#d55e00"))+
    labs(x="Depth (m)",y="Cumulative Proportion",title="",col="Period",fill="Period")
}
```

## Environmental Affinities Ellipses

Functions used to visualize species' environmental affinities to temperature and oxygen.

```{r}
make_spp_concave_hull <- function(ens_preds,yr_vec=1980:2022,sppname,concavity=2,lt=0,threshold=0.05,esm='ipsl'){
  vartemp <- paste0("mean_bt_30d_",esm)
  varoxy <- paste0("mean_oxy_bottom_30d_",esm)
  df <- ens_preds %>% 
    filter(year %in% yr_vec) %>%
    mutate(mean_est=exp(mean_est)) %>%
    filter(mean_est>=quantile(mean_est,threshold)) %>% 
    ungroup() %>% 
    dplyr::select(all_of(c(vartemp,varoxy))) %>% 
    as.matrix()
    # st_as_sf(coords=c("mean_bt_30d_ipsl","mean_oxy_bottom_30d_ipsl"))
  p <- df %>% 
    concaveman(concavity = concavity,length_threshold = lt) %>% 
    as_tibble() %>% 
    mutate(spp=sppname)
  p
}

affinities_ellipses <- function(ens_preds,yr_vec=1980:2022,concavity=3,threshold=0.25,lt=0,return_what='df'){
  df <- ens_preds %>% 
    filter(year %in% yr_vec) %>%
    mutate(mean_est=exp(mean_est)) %>%
    dplyr::select(species,year,mean_est,mean_bt_30d_ipsl,mean_oxy_bottom_30d_ipsl) %>% 
    group_by(species) %>% 
    nest(data=c(year,mean_est,mean_bt_30d_ipsl,mean_oxy_bottom_30d_ipsl)) %>% 
    mutate(p=map(data,make_spp_concave_hull,sppname=species,concavity=concavity,threshold=threshold,lt=lt)) %>% 
    ungroup()
  
  ps <- do.call(rbind,df$p) %>% 
    mutate(spp_plotting=case_when(
      spp=='dover' ~ "Dover Sole",
      spp=="ls" ~ "Longspine",
      spp=="ss"~"Shortspine",
      spp=="sable" ~"Sablefish"
    )) %>% 
    mutate(spp_plotting=factor(spp_plotting,levels=c("Dover Sole","Sablefish","Shortspine","Longspine")))
  
  if(return_what=='plot'){
    out <- ps %>%
      ggplot(aes(V1,V2,col=spp_plotting))+
      geom_polygon(fill=NA,size=1.5)+
      scale_color_manual(values=pal4)+
      # scale_fill_manual(values=pal4)+
      labs(x="Bottom Temperature",y="Bottom Oxygen",col="Species")
  } else{
    out <- ps
  }
  out
}
```

```{r}
# for ensemble (not individual ESMs)
make_spp_concave_hull_ens <- function(ens_preds,yr_vec=1980:2022,sppname,concavity=2,lt=0,threshold=0.05){
  vartemp <- "t_ens"
  varoxy <- "oxy_ens"
  df <- ens_preds %>% 
    filter(year %in% yr_vec) %>%
    mutate(mean_est=exp(mean_est)) %>%
    filter(mean_est>=quantile(mean_est,threshold)) %>% 
    ungroup() %>% 
    dplyr::select(all_of(c(vartemp,varoxy))) %>% 
    as.matrix()
    # st_as_sf(coords=c("mean_bt_30d_ipsl","mean_oxy_bottom_30d_ipsl"))
  p <- df %>% 
    concaveman(concavity = concavity,length_threshold = lt) %>% 
    as_tibble() %>% 
    mutate(spp=sppname)
  p
}

affinities_ellipses_ens <- function(ens_preds,yr_vec=1980:2022,concavity=3,threshold=0.25,lt=0,return_what='df'){
  df <- ens_preds %>% 
    filter(year %in% yr_vec) %>%
    mutate(mean_est=exp(mean_est)) %>%
    dplyr::select(species,year,mean_est,mean_bt_30d_ipsl,mean_oxy_bottom_30d_ipsl,
                  mean_bt_30d_hadl,mean_oxy_bottom_30d_hadl,
                  mean_bt_30d_gfdl,mean_oxy_bottom_30d_gfdl) %>%
    mutate(oxy_ens=(mean_oxy_bottom_30d_ipsl+mean_oxy_bottom_30d_gfdl+mean_oxy_bottom_30d_hadl)/3,
         t_ens=(mean_bt_30d_ipsl+mean_bt_30d_gfdl+mean_bt_30d_hadl)/3) %>% 
    dplyr::select(species,year,mean_est,oxy_ens,t_ens) %>% 
    group_by(species) %>% 
    nest(data=c(year,mean_est,oxy_ens,t_ens)) %>% 
    mutate(p=map(data,make_spp_concave_hull_ens,sppname=species,concavity=concavity,threshold=threshold,lt=lt)) %>% 
    ungroup()
  
  ps <- do.call(rbind,df$p) %>% 
    mutate(spp_plotting=case_when(
      spp=='dover' ~ "Dover Sole",
      spp=="ls" ~ "Longspine",
      spp=="ss"~"Shortspine",
      spp=="sable" ~"Sablefish"
    )) %>% 
    mutate(spp_plotting=factor(spp_plotting,levels=c("Dover Sole","Sablefish","Shortspine","Longspine")))
  
  if(return_what=='plot'){
    out <- ps %>%
      ggplot(aes(V1,V2,col=spp_plotting))+
      geom_polygon(fill=NA,size=1.5)+
      scale_color_manual(values=pal4)+
      # scale_fill_manual(values=pal4)+
      labs(x="Bottom Temperature",y="Bottom Oxygen",col="Species")
  } else{
    out <- ps
  }
  out
}
```

# Fishing Footprints Functions

Functions used to calculate changes in species' projected density within fishing footprints, over time
```{r}
calc_footprint_dens_sims <- function(ens_preds,fp=footprints){
  d <- ens_preds %>%
    filter(year>2019) %>%
    mutate(est=purrr::map(data,exp)) %>%
    # mutate(est=exp(ens_est)) %>%
    st_as_sf(coords=c("longitude","latitude"),crs="+proj=utm +zone=10 +datum=WGS84 +units=km") %>%
    st_join(footprints) %>%
    st_set_geometry(NULL) %>%
    filter(!is.na(port_name)) %>%
    group_by(port_name,year) %>%
    summarise(mean_cpue=purrr::map_dbl(est,mean),
              cpue5=purrr::map_dbl(est,quantile,probs=0.05),
              cpue95=purrr::map_dbl(est,quantile,probs=0.95),
              mean_log_cpue=purrr::map_dbl(data,mean),
              log_cpue5=purrr::map_dbl(data,quantile,probs=0.05),
              log_cpue95=purrr::map_dbl(data,quantile,probs=0.95)) %>%
    ungroup() %>% 
    group_by(port_name,year) %>%
    summarise(mean_cpue=mean(mean_cpue),
              cpue5=mean(cpue5),
              cpue95=mean(cpue95),
              mean_log_cpue=mean(mean_log_cpue),
              log_cpue5=mean(log_cpue5),
              log_cpue95=mean(log_cpue95)) %>% 
    ungroup()
    
  d
}

# calculate species' density relative to historical conditions

calc_footprint_reldens_sims <- function(sims_df,fp=footprints){
 d <- sims_df %>%
   left_join(roms_ports_match,by=c('latitude','longitude')) %>% 
   filter(!is.na(port_name)) %>%
   group_by(year,port_name,esm) %>% 
   summarise(across(contains('sim'),function(x) mean(exp(x)))) %>%
   pivot_longer(contains('sim'),names_to='sim',values_to='cpue_fp') %>% 
   ungroup() %>% 
   dplyr::select(year,esm,port_name,sim,cpue_fp)
 
   # historical mean overlap
  dhist <- d %>% 
    filter(year%in%c(1985:2010)) %>% 
    group_by(sim,esm,port_name) %>% 
    summarise(mean_cpue_hist=mean(cpue_fp)) %>% 
    ungroup()
  
  dfut <- d %>% 
    filter(year%in%c(2075:2100)) %>% 
    group_by(sim,esm,port_name) %>% 
    summarise(mean_cpue_fut=mean(cpue_fp)) %>% 
    ungroup()
    
  d2 <- dhist %>% 
    left_join(dfut,by=c('sim','port_name','esm')) %>% 
    mutate(delta=mean_cpue_fut-mean_cpue_hist,
           delta_perc=delta/mean_cpue_hist*100)
  
  d2
}
```

# Species Overlap

Bhattacharyya's coefficient, calculated on the full dataset of simulations.

```{r}
bhat_sims <- function(sims_df1,sims_df2){
  
  p1 <- sims_df1 %>%
    group_by(year,esm) %>% 
    mutate(across(contains('sim'),function(x) exp(x)/sum(exp(x),na.rm=T))) %>%
    left_join(roms_ports_match,by=c('latitude','longitude')) %>% 
    filter(!is.na(port_name)) %>% 
    pivot_longer(contains('sim'),names_to='sim',values_to='p_p1') %>% 
    dplyr::select(year,esm,port_name,longitude,latitude,sim,p_p1) %>% 
    ungroup()
  
  p2 <- sims_df2 %>%
    group_by(year,esm) %>%
    mutate(across(contains('sim'),function(x) exp(x)/sum(exp(x),na.rm=T))) %>% 
    left_join(roms_ports_match,by=c('latitude','longitude')) %>% 
    filter(!is.na(port_name)) %>% 
    pivot_longer(contains('sim'),names_to='sim',values_to='p_p2') %>% 
    dplyr::select(year,esm,port_name,longitude,latitude,sim,p_p2) %>% 
    ungroup()
  
  pjoint <- p1 %>% 
    left_join(p2,by=c('year','esm','longitude','latitude','port_name','sim')) %>% 
    group_by(year,esm,port_name,sim) %>% 
    summarise(bhat=sum(sqrt(p_p1*p_p2))) %>% 
    ungroup()
  
  pjoint

}
```
